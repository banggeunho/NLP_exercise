{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN-2022-08-06.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOLLd58iPwFGdR2P4Sa9WHK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/banggeunho/nlp_exercise/blob/master/RNN_2022_08_06.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNN 직접 구현\n",
        "![image.png](data:image/png;base64,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)\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "a6Zb4vCOLbAO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oq3ubb0yB4cV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "timesteps = 10\n",
        "input_size = 4\n",
        "hidden_size = 8\n",
        "\n",
        "inputs = np.random.random((timesteps, input_size))\n",
        "hidden_state_t = np.zeros((hidden_size,))\n",
        "\n",
        "Wx = np.random.random((hidden_size, input_size))  # (8, 4)크기의 2D 텐서 생성. 입력에 대한 가중치.\n",
        "Wh = np.random.random((hidden_size, hidden_size)) # (8, 8)크기의 2D 텐서 생성. 은닉 상태에 대한 가중치.\n",
        "b = np.random.random((hidden_size,)) # (8,)크기의 1D 텐서 생성. 이 값은 편향(bias)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_hidden_states = []\n",
        "\n",
        "# 메모리 셀 동작\n",
        "for input_t in inputs: # 각 시점에 따라서 입력값이 입력됨.\n",
        "  output_t = np.tanh(np.dot(Wx,input_t) + np.dot(Wh,hidden_state_t) + b) # Wx * Xt + Wh * Ht-1 + b(bias)\n",
        "  total_hidden_states.append(list(output_t)) # 각 시점의 은닉 상태의 값을 계속해서 축적\n",
        "  print(np.shape(total_hidden_states)) # 각 시점 t별 메모리 셀의 출력의 크기는 (timestep, output_dim)\n",
        "  hidden_state_t = output_t\n",
        "\n",
        "total_hidden_states = np.stack(total_hidden_states, axis = 0) \n",
        "# 출력 시 값을 깔끔하게 해준다.\n",
        "\n",
        "print(total_hidden_states) # (timesteps, output_dim)의 크기. 이 경우 (10, 8)의 크기를 가지는 메모리 셀의 2D 텐서를 출력."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0qbUSjuEbFl",
        "outputId": "b0e48344-876a-4aec-f2c2-90bc12a109b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 8)\n",
            "(2, 8)\n",
            "(3, 8)\n",
            "(4, 8)\n",
            "(5, 8)\n",
            "(6, 8)\n",
            "(7, 8)\n",
            "(8, 8)\n",
            "(9, 8)\n",
            "(10, 8)\n",
            "[[0.65561297 0.84275573 0.83057582 0.83452184 0.77428007 0.92567259\n",
            "  0.9509507  0.8972495 ]\n",
            " [0.99956128 0.999925   0.9995511  0.99960121 0.998677   0.99997235\n",
            "  0.99939961 0.9996033 ]\n",
            " [0.99977542 0.9999859  0.99961851 0.99988648 0.99961383 0.99999868\n",
            "  0.99970739 0.99987852]\n",
            " [0.99991334 0.99998795 0.99990314 0.99991275 0.99971272 0.99999761\n",
            "  0.99989494 0.99995045]\n",
            " [0.99987941 0.99998653 0.99980545 0.99987774 0.99961785 0.9999975\n",
            "  0.99978182 0.99992702]\n",
            " [0.99969581 0.99996801 0.99977969 0.99975514 0.99919537 0.99999488\n",
            "  0.99954358 0.99960519]\n",
            " [0.99987494 0.9999917  0.99988101 0.99995783 0.99978705 0.99999911\n",
            "  0.99987929 0.99990375]\n",
            " [0.99954254 0.99996756 0.9995888  0.99974687 0.99916533 0.99999664\n",
            "  0.9993776  0.99949622]\n",
            " [0.99984117 0.99998426 0.99982714 0.99987855 0.99954133 0.99999713\n",
            "  0.99970335 0.9998361 ]\n",
            " [0.99986253 0.99999155 0.99982674 0.99995455 0.99981776 0.99999939\n",
            "  0.99991649 0.99994877]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Torch에서 제공하는 RNN"
      ],
      "metadata": {
        "id": "K4pB-aeYLelo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "hDPovERAFIFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 5 # 입력의 크기\n",
        "hidden_size = 8 # 은닉 상태의 크기"
      ],
      "metadata": {
        "id": "eU5_01KnFJTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (batch_size, time_steps, input_size)\n",
        "inputs = torch.Tensor(1, 10, 5)\n",
        "cell = nn.RNN(input_size, hidden_size, batch_first=True)\n",
        "outputs, _status = cell(inputs)\n",
        "print(outputs.shape) # 모든 time-step의 hidden_state\n",
        "print(_status.shape) # 최종 time-step의 hidden_state"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7C-ThV4YFKus",
        "outputId": "11985007-b2e9-460f-8a77-414382de96c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 10, 8])\n",
            "torch.Size([1, 1, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cell = nn.RNN(input_size = 5, hidden_size = 8, num_layers = 2, batch_first=True)\n",
        "outputs, _status = cell(inputs)\n",
        "print(outputs.shape) # 모든 time-step의 hidden_state\n",
        "print(_status.shape) # (층의 개수, 배치 크기, 은닉 상태의 크기)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dX0jl-XuF5RJ",
        "outputId": "52b8f98f-9cb0-46e1-8ac7-788bb0d7342e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 10, 8])\n",
            "torch.Size([2, 1, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cell = nn.RNN(input_size = 5, hidden_size = 8, num_layers = 2, batch_first=True, bidirectional = True)\n",
        "outputs, _status = cell(inputs)\n",
        "print(outputs.shape) # (배치 크기, 시퀀스 길이, 은닉 상태의 크기 x 2)\n",
        "print(_status.shape) # (층의 개수 x 2, 배치 크기, 은닉 상태의 크기)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEhmNGXBI28U",
        "outputId": "41ee5abb-ef80-4d12-f6c7-5416504b7976"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 10, 16])\n",
            "torch.Size([4, 1, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_VVIFM0hLux6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM\n"
      ],
      "metadata": {
        "id": "cTf5DPDzLX6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nn.LSTM(input_dim, hidden_size, batch_fisrt=True)  "
      ],
      "metadata": {
        "id": "2gZnQXtwLhR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "xzP7u65wPz0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_str = 'apple'\n",
        "label_str = 'pple!'\n",
        "char_vocab = sorted(list(set(input_str+label_str)))\n",
        "vocab_size = len(char_vocab)\n",
        "print(char_vocab)\n",
        "print ('문자 집합의 크기 : {}'.format(vocab_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q58Dt5qzP1N_",
        "outputId": "dfcbe1b4-e091-4895-adac-8915f2b79618"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['!', 'a', 'e', 'l', 'p']\n",
            "문자 집합의 크기 : 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = vocab_size # 입력의 크기는 문자 집합의 크기\n",
        "hidden_size = 5\n",
        "output_size = 5\n",
        "learning_rate = 0.1\n",
        "\n",
        "char_to_index = dict((c, i) for i, c in enumerate(char_vocab)) # 문자에 고유한 정수 인덱스 부여\n",
        "print(char_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzXPlcNMQNso",
        "outputId": "3006b88b-741c-4dc3-b02e-c24c77ebc379"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'!': 0, 'a': 1, 'e': 2, 'l': 3, 'p': 4}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_char={}\n",
        "for key, value in char_to_index.items():\n",
        "    index_to_char[value] = key\n",
        "print(index_to_char)\n",
        "\n",
        "x_data = [char_to_index[c] for c in input_str]\n",
        "y_data = [char_to_index[c] for c in label_str]\n",
        "print(x_data)\n",
        "print(y_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WJipp0UQSkB",
        "outputId": "5647394c-c174-4852-9c44-fe82765f1e93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: '!', 1: 'a', 2: 'e', 3: 'l', 4: 'p'}\n",
            "[1, 4, 4, 3, 2]\n",
            "[4, 4, 3, 2, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 배치 차원 추가 -> RNN은 기본적으로 3차원 텐서를 입력 받습니다.\n",
        "# 텐서 연산인 unsqueeze(0)를 통해 해결할 수도 있었음.\n",
        "x_data = [x_data]\n",
        "y_data = [y_data]\n",
        "print(x_data)\n",
        "print(y_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwVl1ggNQc0y",
        "outputId": "88e78c6c-1970-4df9-b343-2c3618977f46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 4, 4, 3, 2]]\n",
            "[[4, 4, 3, 2, 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_one_hot = [np.eye(vocab_size)[x] for x in x_data] # np.eye(size) -> 원핫벡터 만들기\n",
        "print(x_one_hot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMNB6y61RMvX",
        "outputId": "a95db039-f0a7-45ee-dd54-7d542a3b5019"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([[0., 1., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 1.],\n",
            "       [0., 0., 0., 0., 1.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [0., 0., 1., 0., 0.]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.FloatTensor(x_one_hot)\n",
        "Y = torch.LongTensor(y_data)\n",
        "print('훈련 데이터의 크기 : {}'.format(X.shape))\n",
        "print('레이블의 크기 : {}'.format(Y.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8J7OiQNhRZjp",
        "outputId": "cf77252c-0011-41e1-9468-c383829a2740"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 데이터의 크기 : torch.Size([1, 5, 5])\n",
            "레이블의 크기 : torch.Size([1, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(Net, self).__init__()\n",
        "        self.rnn = torch.nn.RNN(input_size, hidden_size, batch_first=True) # RNN 셀 구현\n",
        "        self.fc = torch.nn.Linear(hidden_size, output_size, bias=True) # 출력층 구현\n",
        "\n",
        "    def forward(self, x): # 구현한 RNN 셀과 출력층을 연결\n",
        "        x, _status = self.rnn(x)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "2EMP2nAtRfuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net(input_size, hidden_size, output_size)"
      ],
      "metadata": {
        "id": "FmgLTRwNRhh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = net(X)\n",
        "print(outputs.shape) # 3차원 텐서"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Pu9N77rRiym",
        "outputId": "32aee01c-fa17-4ec9-c309-53b0ecb84292"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 5, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs.view(-1, input_size).shape) # 2차원 텐서로 변환"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvQsHZRORkEh",
        "outputId": "1fec4b19-5884-44a5-df87-1062a0f1e255"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), learning_rate)"
      ],
      "metadata": {
        "id": "Flx7Uu8nRvoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(X)\n",
        "    loss = criterion(outputs.view(-1, input_size), Y.view(-1)) # view를 하는 이유는 Batch 차원 제거를 위해\n",
        "    loss.backward() # 기울기 계산\n",
        "    optimizer.step() # 아까 optimizer 선언 시 넣어둔 파라미터 업데이트\n",
        "\n",
        "    # 아래 세 줄은 모델이 실제 어떻게 예측했는지를 확인하기 위한 코드.\n",
        "    result = outputs.data.numpy().argmax(axis=2) # 최종 예측값인 각 time-step 별 5차원 벡터에 대해서 가장 높은 값의 인덱스를 선택\n",
        "    result_str = ''.join([index_to_char[c] for c in np.squeeze(result)])\n",
        "    print(i, \"loss: \", loss.item(), \"prediction: \", result, \"true Y: \", y_data, \"prediction str: \", result_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Bm3MdmeRwhG",
        "outputId": "45a52493-0510-423e-c82c-fb9c52ecc818"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 loss:  1.5890038013458252 prediction:  [[3 4 4 4 4]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  lpppp\n",
            "1 loss:  1.3977162837982178 prediction:  [[4 4 4 4 4]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  ppppp\n",
            "2 loss:  1.2782354354858398 prediction:  [[4 4 4 4 4]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  ppppp\n",
            "3 loss:  1.1340086460113525 prediction:  [[4 4 4 2 4]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pppep\n",
            "4 loss:  0.9301871061325073 prediction:  [[4 4 4 2 4]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pppep\n",
            "5 loss:  0.7169126868247986 prediction:  [[4 4 4 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pppe!\n",
            "6 loss:  0.5184742212295532 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "7 loss:  0.3757351040840149 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "8 loss:  0.264345645904541 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "9 loss:  0.19731785356998444 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "10 loss:  0.13799701631069183 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "11 loss:  0.09891585260629654 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "12 loss:  0.07282581925392151 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "13 loss:  0.05146654322743416 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "14 loss:  0.03718504682183266 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "15 loss:  0.028968602418899536 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "16 loss:  0.02296537160873413 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "17 loss:  0.017462193965911865 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "18 loss:  0.013296419754624367 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "19 loss:  0.010567652992904186 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "20 loss:  0.008755882270634174 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "21 loss:  0.007444670889526606 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "22 loss:  0.006385812070220709 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "23 loss:  0.005453614518046379 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "24 loss:  0.004617591388523579 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "25 loss:  0.0038980611134320498 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "26 loss:  0.0033172741532325745 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "27 loss:  0.0028771287761628628 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "28 loss:  0.0025626339484006166 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "29 loss:  0.002349029527977109 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "30 loss:  0.002203657990321517 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "31 loss:  0.0020849884022027254 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "32 loss:  0.0019549757707864046 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "33 loss:  0.0018034589011222124 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "34 loss:  0.0016500490019097924 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "35 loss:  0.0015179258771240711 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "36 loss:  0.00141616677865386 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "37 loss:  0.0013419556198641658 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "38 loss:  0.0012876861728727818 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "39 loss:  0.0012452224036678672 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "40 loss:  0.0012082593748345971 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "41 loss:  0.0011723701609298587 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "42 loss:  0.0011353174922987819 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "43 loss:  0.0010967906564474106 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "44 loss:  0.0010578831424936652 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "45 loss:  0.0010199745884165168 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "46 loss:  0.0009846597677096725 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "47 loss:  0.0009529385715723038 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "48 loss:  0.0009254544856958091 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "49 loss:  0.0009021367877721786 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "50 loss:  0.0008827479323372245 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "51 loss:  0.0008665738860145211 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "52 loss:  0.0008527097525075078 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "53 loss:  0.0008403222891502082 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "54 loss:  0.0008285065414384007 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "55 loss:  0.0008168097701855004 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "56 loss:  0.0008048987947404385 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "57 loss:  0.0007927257684059441 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "58 loss:  0.0007806479698047042 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "59 loss:  0.0007688322220928967 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "60 loss:  0.0007576833595521748 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "61 loss:  0.0007473682053387165 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "62 loss:  0.0007379581802524626 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "63 loss:  0.0007294771494343877 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "64 loss:  0.0007217821548692882 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "65 loss:  0.0007148018339648843 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "66 loss:  0.0007083693635649979 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "67 loss:  0.0007022464997135103 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "68 loss:  0.0006963858031667769 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "69 loss:  0.0006906917551532388 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "70 loss:  0.0006850929348729551 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "71 loss:  0.0006796370726078749 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "72 loss:  0.0006742288242094219 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "73 loss:  0.0006688681896775961 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "74 loss:  0.0006636742618866265 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "75 loss:  0.0006586947711184621 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "76 loss:  0.0006539057940244675 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "77 loss:  0.0006493311375379562 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "78 loss:  0.0006449948414228857 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "79 loss:  0.000640896731056273 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "80 loss:  0.0006369892507791519 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "81 loss:  0.0006332246121019125 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "82 loss:  0.0006295791827142239 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "83 loss:  0.0006260766531340778 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "84 loss:  0.0006226217374205589 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "85 loss:  0.0006191906868480146 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "86 loss:  0.0006158549222163856 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "87 loss:  0.000612543080933392 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "88 loss:  0.0006092788535170257 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "89 loss:  0.0006060145678929985 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "90 loss:  0.0006028456846252084 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "91 loss:  0.0005997481639496982 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "92 loss:  0.0005967222386971116 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "93 loss:  0.0005937676760368049 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "94 loss:  0.000590884534176439 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "95 loss:  0.0005880491808056831 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "96 loss:  0.000585237517952919 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "97 loss:  0.000582473527174443 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "98 loss:  0.0005797571502625942 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "99 loss:  0.0005770884454250336 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 문자 단위 RNN (Many to Many) - 더 많은 데이터"
      ],
      "metadata": {
        "id": "qQZCakyeIqyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "f2aZQMxEIrv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = (\"if you want to build a ship, don't drum up people together to \"\n",
        "            \"collect wood and don't assign them tasks and work, but rather \"\n",
        "            \"teach them to long for the endless immensity of the sea.\")"
      ],
      "metadata": {
        "id": "vmzOwo1jIyfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "char_set = list(set(sentence)) # 중복을 제거한 문자 집합 생성\n",
        "char_dic = {c: i for i, c in enumerate(char_set)} # 각 문자에 정수 인코딩\n",
        "\n",
        "dic_size = len(char_dic)\n",
        "print(char_dic)\n",
        "print('문자 집합의 크기 : {}'.format(dic_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "va6WPoMmI0mf",
        "outputId": "a3cda780-6b34-45f8-8303-4d5952bdb57b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'y': 0, 'u': 1, 'w': 2, 'r': 3, 't': 4, \"'\": 5, 'o': 6, 'f': 7, 'b': 8, 'd': 9, 'g': 10, 'k': 11, 'i': 12, 'e': 13, ' ': 14, 'l': 15, 'p': 16, 'h': 17, 's': 18, 'a': 19, 'c': 20, 'm': 21, ',': 22, '.': 23, 'n': 24}\n",
            "문자 집합의 크기 : 25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼파라미터 설정\n",
        "hidden_size = dic_size\n",
        "sequence_length = 10  # 임의 숫자 지정\n",
        "learning_rate = 0.1"
      ],
      "metadata": {
        "id": "lH6aFiA0I5lT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 구성\n",
        "x_data = []\n",
        "y_data = []\n",
        "\n",
        "for i in range(0, len(sentence) - sequence_length):\n",
        "    x_str = sentence[i:i + sequence_length]\n",
        "    y_str = sentence[i + 1: i + sequence_length + 1]\n",
        "    print(i, x_str, '->', y_str)\n",
        "\n",
        "    x_data.append([char_dic[c] for c in x_str])  # x str to index\n",
        "    y_data.append([char_dic[c] for c in y_str])  # y str to index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwcjdoAbJAXL",
        "outputId": "ff8a420d-834d-4c9a-824f-05d8e80a267a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 if you wan -> f you want\n",
            "1 f you want ->  you want \n",
            "2  you want  -> you want t\n",
            "3 you want t -> ou want to\n",
            "4 ou want to -> u want to \n",
            "5 u want to  ->  want to b\n",
            "6  want to b -> want to bu\n",
            "7 want to bu -> ant to bui\n",
            "8 ant to bui -> nt to buil\n",
            "9 nt to buil -> t to build\n",
            "10 t to build ->  to build \n",
            "11  to build  -> to build a\n",
            "12 to build a -> o build a \n",
            "13 o build a  ->  build a s\n",
            "14  build a s -> build a sh\n",
            "15 build a sh -> uild a shi\n",
            "16 uild a shi -> ild a ship\n",
            "17 ild a ship -> ld a ship,\n",
            "18 ld a ship, -> d a ship, \n",
            "19 d a ship,  ->  a ship, d\n",
            "20  a ship, d -> a ship, do\n",
            "21 a ship, do ->  ship, don\n",
            "22  ship, don -> ship, don'\n",
            "23 ship, don' -> hip, don't\n",
            "24 hip, don't -> ip, don't \n",
            "25 ip, don't  -> p, don't d\n",
            "26 p, don't d -> , don't dr\n",
            "27 , don't dr ->  don't dru\n",
            "28  don't dru -> don't drum\n",
            "29 don't drum -> on't drum \n",
            "30 on't drum  -> n't drum u\n",
            "31 n't drum u -> 't drum up\n",
            "32 't drum up -> t drum up \n",
            "33 t drum up  ->  drum up p\n",
            "34  drum up p -> drum up pe\n",
            "35 drum up pe -> rum up peo\n",
            "36 rum up peo -> um up peop\n",
            "37 um up peop -> m up peopl\n",
            "38 m up peopl ->  up people\n",
            "39  up people -> up people \n",
            "40 up people  -> p people t\n",
            "41 p people t ->  people to\n",
            "42  people to -> people tog\n",
            "43 people tog -> eople toge\n",
            "44 eople toge -> ople toget\n",
            "45 ople toget -> ple togeth\n",
            "46 ple togeth -> le togethe\n",
            "47 le togethe -> e together\n",
            "48 e together ->  together \n",
            "49  together  -> together t\n",
            "50 together t -> ogether to\n",
            "51 ogether to -> gether to \n",
            "52 gether to  -> ether to c\n",
            "53 ether to c -> ther to co\n",
            "54 ther to co -> her to col\n",
            "55 her to col -> er to coll\n",
            "56 er to coll -> r to colle\n",
            "57 r to colle ->  to collec\n",
            "58  to collec -> to collect\n",
            "59 to collect -> o collect \n",
            "60 o collect  ->  collect w\n",
            "61  collect w -> collect wo\n",
            "62 collect wo -> ollect woo\n",
            "63 ollect woo -> llect wood\n",
            "64 llect wood -> lect wood \n",
            "65 lect wood  -> ect wood a\n",
            "66 ect wood a -> ct wood an\n",
            "67 ct wood an -> t wood and\n",
            "68 t wood and ->  wood and \n",
            "69  wood and  -> wood and d\n",
            "70 wood and d -> ood and do\n",
            "71 ood and do -> od and don\n",
            "72 od and don -> d and don'\n",
            "73 d and don' ->  and don't\n",
            "74  and don't -> and don't \n",
            "75 and don't  -> nd don't a\n",
            "76 nd don't a -> d don't as\n",
            "77 d don't as ->  don't ass\n",
            "78  don't ass -> don't assi\n",
            "79 don't assi -> on't assig\n",
            "80 on't assig -> n't assign\n",
            "81 n't assign -> 't assign \n",
            "82 't assign  -> t assign t\n",
            "83 t assign t ->  assign th\n",
            "84  assign th -> assign the\n",
            "85 assign the -> ssign them\n",
            "86 ssign them -> sign them \n",
            "87 sign them  -> ign them t\n",
            "88 ign them t -> gn them ta\n",
            "89 gn them ta -> n them tas\n",
            "90 n them tas ->  them task\n",
            "91  them task -> them tasks\n",
            "92 them tasks -> hem tasks \n",
            "93 hem tasks  -> em tasks a\n",
            "94 em tasks a -> m tasks an\n",
            "95 m tasks an ->  tasks and\n",
            "96  tasks and -> tasks and \n",
            "97 tasks and  -> asks and w\n",
            "98 asks and w -> sks and wo\n",
            "99 sks and wo -> ks and wor\n",
            "100 ks and wor -> s and work\n",
            "101 s and work ->  and work,\n",
            "102  and work, -> and work, \n",
            "103 and work,  -> nd work, b\n",
            "104 nd work, b -> d work, bu\n",
            "105 d work, bu ->  work, but\n",
            "106  work, but -> work, but \n",
            "107 work, but  -> ork, but r\n",
            "108 ork, but r -> rk, but ra\n",
            "109 rk, but ra -> k, but rat\n",
            "110 k, but rat -> , but rath\n",
            "111 , but rath ->  but rathe\n",
            "112  but rathe -> but rather\n",
            "113 but rather -> ut rather \n",
            "114 ut rather  -> t rather t\n",
            "115 t rather t ->  rather te\n",
            "116  rather te -> rather tea\n",
            "117 rather tea -> ather teac\n",
            "118 ather teac -> ther teach\n",
            "119 ther teach -> her teach \n",
            "120 her teach  -> er teach t\n",
            "121 er teach t -> r teach th\n",
            "122 r teach th ->  teach the\n",
            "123  teach the -> teach them\n",
            "124 teach them -> each them \n",
            "125 each them  -> ach them t\n",
            "126 ach them t -> ch them to\n",
            "127 ch them to -> h them to \n",
            "128 h them to  ->  them to l\n",
            "129  them to l -> them to lo\n",
            "130 them to lo -> hem to lon\n",
            "131 hem to lon -> em to long\n",
            "132 em to long -> m to long \n",
            "133 m to long  ->  to long f\n",
            "134  to long f -> to long fo\n",
            "135 to long fo -> o long for\n",
            "136 o long for ->  long for \n",
            "137  long for  -> long for t\n",
            "138 long for t -> ong for th\n",
            "139 ong for th -> ng for the\n",
            "140 ng for the -> g for the \n",
            "141 g for the  ->  for the e\n",
            "142  for the e -> for the en\n",
            "143 for the en -> or the end\n",
            "144 or the end -> r the endl\n",
            "145 r the endl ->  the endle\n",
            "146  the endle -> the endles\n",
            "147 the endles -> he endless\n",
            "148 he endless -> e endless \n",
            "149 e endless  ->  endless i\n",
            "150  endless i -> endless im\n",
            "151 endless im -> ndless imm\n",
            "152 ndless imm -> dless imme\n",
            "153 dless imme -> less immen\n",
            "154 less immen -> ess immens\n",
            "155 ess immens -> ss immensi\n",
            "156 ss immensi -> s immensit\n",
            "157 s immensit ->  immensity\n",
            "158  immensity -> immensity \n",
            "159 immensity  -> mmensity o\n",
            "160 mmensity o -> mensity of\n",
            "161 mensity of -> ensity of \n",
            "162 ensity of  -> nsity of t\n",
            "163 nsity of t -> sity of th\n",
            "164 sity of th -> ity of the\n",
            "165 ity of the -> ty of the \n",
            "166 ty of the  -> y of the s\n",
            "167 y of the s ->  of the se\n",
            "168  of the se -> of the sea\n",
            "169 of the sea -> f the sea.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_one_hot = [np.eye(dic_size)[x] for x in x_data] # x 데이터는 원-핫 인코딩\n",
        "X = torch.FloatTensor(x_one_hot)\n",
        "Y = torch.LongTensor(y_data)\n",
        "\n",
        "print(x_data)\n",
        "print(X[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FspYlrfgJPFh",
        "outputId": "47e09e4c-f714-4095-e16a-f16fb5dfb62c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[12, 7, 14, 0, 6, 1, 14, 2, 19, 24], [7, 14, 0, 6, 1, 14, 2, 19, 24, 4], [14, 0, 6, 1, 14, 2, 19, 24, 4, 14], [0, 6, 1, 14, 2, 19, 24, 4, 14, 4], [6, 1, 14, 2, 19, 24, 4, 14, 4, 6], [1, 14, 2, 19, 24, 4, 14, 4, 6, 14], [14, 2, 19, 24, 4, 14, 4, 6, 14, 8], [2, 19, 24, 4, 14, 4, 6, 14, 8, 1], [19, 24, 4, 14, 4, 6, 14, 8, 1, 12], [24, 4, 14, 4, 6, 14, 8, 1, 12, 15], [4, 14, 4, 6, 14, 8, 1, 12, 15, 9], [14, 4, 6, 14, 8, 1, 12, 15, 9, 14], [4, 6, 14, 8, 1, 12, 15, 9, 14, 19], [6, 14, 8, 1, 12, 15, 9, 14, 19, 14], [14, 8, 1, 12, 15, 9, 14, 19, 14, 18], [8, 1, 12, 15, 9, 14, 19, 14, 18, 17], [1, 12, 15, 9, 14, 19, 14, 18, 17, 12], [12, 15, 9, 14, 19, 14, 18, 17, 12, 16], [15, 9, 14, 19, 14, 18, 17, 12, 16, 22], [9, 14, 19, 14, 18, 17, 12, 16, 22, 14], [14, 19, 14, 18, 17, 12, 16, 22, 14, 9], [19, 14, 18, 17, 12, 16, 22, 14, 9, 6], [14, 18, 17, 12, 16, 22, 14, 9, 6, 24], [18, 17, 12, 16, 22, 14, 9, 6, 24, 5], [17, 12, 16, 22, 14, 9, 6, 24, 5, 4], [12, 16, 22, 14, 9, 6, 24, 5, 4, 14], [16, 22, 14, 9, 6, 24, 5, 4, 14, 9], [22, 14, 9, 6, 24, 5, 4, 14, 9, 3], [14, 9, 6, 24, 5, 4, 14, 9, 3, 1], [9, 6, 24, 5, 4, 14, 9, 3, 1, 21], [6, 24, 5, 4, 14, 9, 3, 1, 21, 14], [24, 5, 4, 14, 9, 3, 1, 21, 14, 1], [5, 4, 14, 9, 3, 1, 21, 14, 1, 16], [4, 14, 9, 3, 1, 21, 14, 1, 16, 14], [14, 9, 3, 1, 21, 14, 1, 16, 14, 16], [9, 3, 1, 21, 14, 1, 16, 14, 16, 13], [3, 1, 21, 14, 1, 16, 14, 16, 13, 6], [1, 21, 14, 1, 16, 14, 16, 13, 6, 16], [21, 14, 1, 16, 14, 16, 13, 6, 16, 15], [14, 1, 16, 14, 16, 13, 6, 16, 15, 13], [1, 16, 14, 16, 13, 6, 16, 15, 13, 14], [16, 14, 16, 13, 6, 16, 15, 13, 14, 4], [14, 16, 13, 6, 16, 15, 13, 14, 4, 6], [16, 13, 6, 16, 15, 13, 14, 4, 6, 10], [13, 6, 16, 15, 13, 14, 4, 6, 10, 13], [6, 16, 15, 13, 14, 4, 6, 10, 13, 4], [16, 15, 13, 14, 4, 6, 10, 13, 4, 17], [15, 13, 14, 4, 6, 10, 13, 4, 17, 13], [13, 14, 4, 6, 10, 13, 4, 17, 13, 3], [14, 4, 6, 10, 13, 4, 17, 13, 3, 14], [4, 6, 10, 13, 4, 17, 13, 3, 14, 4], [6, 10, 13, 4, 17, 13, 3, 14, 4, 6], [10, 13, 4, 17, 13, 3, 14, 4, 6, 14], [13, 4, 17, 13, 3, 14, 4, 6, 14, 20], [4, 17, 13, 3, 14, 4, 6, 14, 20, 6], [17, 13, 3, 14, 4, 6, 14, 20, 6, 15], [13, 3, 14, 4, 6, 14, 20, 6, 15, 15], [3, 14, 4, 6, 14, 20, 6, 15, 15, 13], [14, 4, 6, 14, 20, 6, 15, 15, 13, 20], [4, 6, 14, 20, 6, 15, 15, 13, 20, 4], [6, 14, 20, 6, 15, 15, 13, 20, 4, 14], [14, 20, 6, 15, 15, 13, 20, 4, 14, 2], [20, 6, 15, 15, 13, 20, 4, 14, 2, 6], [6, 15, 15, 13, 20, 4, 14, 2, 6, 6], [15, 15, 13, 20, 4, 14, 2, 6, 6, 9], [15, 13, 20, 4, 14, 2, 6, 6, 9, 14], [13, 20, 4, 14, 2, 6, 6, 9, 14, 19], [20, 4, 14, 2, 6, 6, 9, 14, 19, 24], [4, 14, 2, 6, 6, 9, 14, 19, 24, 9], [14, 2, 6, 6, 9, 14, 19, 24, 9, 14], [2, 6, 6, 9, 14, 19, 24, 9, 14, 9], [6, 6, 9, 14, 19, 24, 9, 14, 9, 6], [6, 9, 14, 19, 24, 9, 14, 9, 6, 24], [9, 14, 19, 24, 9, 14, 9, 6, 24, 5], [14, 19, 24, 9, 14, 9, 6, 24, 5, 4], [19, 24, 9, 14, 9, 6, 24, 5, 4, 14], [24, 9, 14, 9, 6, 24, 5, 4, 14, 19], [9, 14, 9, 6, 24, 5, 4, 14, 19, 18], [14, 9, 6, 24, 5, 4, 14, 19, 18, 18], [9, 6, 24, 5, 4, 14, 19, 18, 18, 12], [6, 24, 5, 4, 14, 19, 18, 18, 12, 10], [24, 5, 4, 14, 19, 18, 18, 12, 10, 24], [5, 4, 14, 19, 18, 18, 12, 10, 24, 14], [4, 14, 19, 18, 18, 12, 10, 24, 14, 4], [14, 19, 18, 18, 12, 10, 24, 14, 4, 17], [19, 18, 18, 12, 10, 24, 14, 4, 17, 13], [18, 18, 12, 10, 24, 14, 4, 17, 13, 21], [18, 12, 10, 24, 14, 4, 17, 13, 21, 14], [12, 10, 24, 14, 4, 17, 13, 21, 14, 4], [10, 24, 14, 4, 17, 13, 21, 14, 4, 19], [24, 14, 4, 17, 13, 21, 14, 4, 19, 18], [14, 4, 17, 13, 21, 14, 4, 19, 18, 11], [4, 17, 13, 21, 14, 4, 19, 18, 11, 18], [17, 13, 21, 14, 4, 19, 18, 11, 18, 14], [13, 21, 14, 4, 19, 18, 11, 18, 14, 19], [21, 14, 4, 19, 18, 11, 18, 14, 19, 24], [14, 4, 19, 18, 11, 18, 14, 19, 24, 9], [4, 19, 18, 11, 18, 14, 19, 24, 9, 14], [19, 18, 11, 18, 14, 19, 24, 9, 14, 2], [18, 11, 18, 14, 19, 24, 9, 14, 2, 6], [11, 18, 14, 19, 24, 9, 14, 2, 6, 3], [18, 14, 19, 24, 9, 14, 2, 6, 3, 11], [14, 19, 24, 9, 14, 2, 6, 3, 11, 22], [19, 24, 9, 14, 2, 6, 3, 11, 22, 14], [24, 9, 14, 2, 6, 3, 11, 22, 14, 8], [9, 14, 2, 6, 3, 11, 22, 14, 8, 1], [14, 2, 6, 3, 11, 22, 14, 8, 1, 4], [2, 6, 3, 11, 22, 14, 8, 1, 4, 14], [6, 3, 11, 22, 14, 8, 1, 4, 14, 3], [3, 11, 22, 14, 8, 1, 4, 14, 3, 19], [11, 22, 14, 8, 1, 4, 14, 3, 19, 4], [22, 14, 8, 1, 4, 14, 3, 19, 4, 17], [14, 8, 1, 4, 14, 3, 19, 4, 17, 13], [8, 1, 4, 14, 3, 19, 4, 17, 13, 3], [1, 4, 14, 3, 19, 4, 17, 13, 3, 14], [4, 14, 3, 19, 4, 17, 13, 3, 14, 4], [14, 3, 19, 4, 17, 13, 3, 14, 4, 13], [3, 19, 4, 17, 13, 3, 14, 4, 13, 19], [19, 4, 17, 13, 3, 14, 4, 13, 19, 20], [4, 17, 13, 3, 14, 4, 13, 19, 20, 17], [17, 13, 3, 14, 4, 13, 19, 20, 17, 14], [13, 3, 14, 4, 13, 19, 20, 17, 14, 4], [3, 14, 4, 13, 19, 20, 17, 14, 4, 17], [14, 4, 13, 19, 20, 17, 14, 4, 17, 13], [4, 13, 19, 20, 17, 14, 4, 17, 13, 21], [13, 19, 20, 17, 14, 4, 17, 13, 21, 14], [19, 20, 17, 14, 4, 17, 13, 21, 14, 4], [20, 17, 14, 4, 17, 13, 21, 14, 4, 6], [17, 14, 4, 17, 13, 21, 14, 4, 6, 14], [14, 4, 17, 13, 21, 14, 4, 6, 14, 15], [4, 17, 13, 21, 14, 4, 6, 14, 15, 6], [17, 13, 21, 14, 4, 6, 14, 15, 6, 24], [13, 21, 14, 4, 6, 14, 15, 6, 24, 10], [21, 14, 4, 6, 14, 15, 6, 24, 10, 14], [14, 4, 6, 14, 15, 6, 24, 10, 14, 7], [4, 6, 14, 15, 6, 24, 10, 14, 7, 6], [6, 14, 15, 6, 24, 10, 14, 7, 6, 3], [14, 15, 6, 24, 10, 14, 7, 6, 3, 14], [15, 6, 24, 10, 14, 7, 6, 3, 14, 4], [6, 24, 10, 14, 7, 6, 3, 14, 4, 17], [24, 10, 14, 7, 6, 3, 14, 4, 17, 13], [10, 14, 7, 6, 3, 14, 4, 17, 13, 14], [14, 7, 6, 3, 14, 4, 17, 13, 14, 13], [7, 6, 3, 14, 4, 17, 13, 14, 13, 24], [6, 3, 14, 4, 17, 13, 14, 13, 24, 9], [3, 14, 4, 17, 13, 14, 13, 24, 9, 15], [14, 4, 17, 13, 14, 13, 24, 9, 15, 13], [4, 17, 13, 14, 13, 24, 9, 15, 13, 18], [17, 13, 14, 13, 24, 9, 15, 13, 18, 18], [13, 14, 13, 24, 9, 15, 13, 18, 18, 14], [14, 13, 24, 9, 15, 13, 18, 18, 14, 12], [13, 24, 9, 15, 13, 18, 18, 14, 12, 21], [24, 9, 15, 13, 18, 18, 14, 12, 21, 21], [9, 15, 13, 18, 18, 14, 12, 21, 21, 13], [15, 13, 18, 18, 14, 12, 21, 21, 13, 24], [13, 18, 18, 14, 12, 21, 21, 13, 24, 18], [18, 18, 14, 12, 21, 21, 13, 24, 18, 12], [18, 14, 12, 21, 21, 13, 24, 18, 12, 4], [14, 12, 21, 21, 13, 24, 18, 12, 4, 0], [12, 21, 21, 13, 24, 18, 12, 4, 0, 14], [21, 21, 13, 24, 18, 12, 4, 0, 14, 6], [21, 13, 24, 18, 12, 4, 0, 14, 6, 7], [13, 24, 18, 12, 4, 0, 14, 6, 7, 14], [24, 18, 12, 4, 0, 14, 6, 7, 14, 4], [18, 12, 4, 0, 14, 6, 7, 14, 4, 17], [12, 4, 0, 14, 6, 7, 14, 4, 17, 13], [4, 0, 14, 6, 7, 14, 4, 17, 13, 14], [0, 14, 6, 7, 14, 4, 17, 13, 14, 18], [14, 6, 7, 14, 4, 17, 13, 14, 18, 13], [6, 7, 14, 4, 17, 13, 14, 18, 13, 19]]\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, layers): # 현재 hidden_size는 dic_size와 같음.\n",
        "        super(Net, self).__init__()\n",
        "        self.rnn = torch.nn.RNN(input_dim, hidden_dim, num_layers=layers, batch_first=True)\n",
        "        self.fc = torch.nn.Linear(hidden_dim, hidden_dim, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, _status = self.rnn(x)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "WsoZdHk1JySX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net1 = Net(dic_size, hidden_size, 2) # 이번에는 층을 두 개 쌓습니다.\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), learning_rate)\n",
        "outputs = net1(X)\n",
        "print(X.shape)\n",
        "print(outputs.shape) # 3차원 텐서"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMinwWFcJ1kJ",
        "outputId": "1c505bd1-752d-4af8-ae71-175cd9e6107d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([170, 10, 25])\n",
            "torch.Size([170, 10, 25])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(X) # (170, 10, 25) 크기를 가진 텐서를 매 에포크마다 모델의 입력으로 사용\n",
        "    loss = criterion(outputs.view(-1, dic_size), Y.view(-1))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # results의 텐서 크기는 (170, 10)\n",
        "    results = outputs.argmax(dim=2)\n",
        "    predict_str = \"\"\n",
        "    for j, result in enumerate(results):\n",
        "        if j == 0: # 처음에는 예측 결과를 전부 가져오지만\n",
        "            predict_str += ''.join([char_set[t] for t in result])\n",
        "        else: # 그 다음에는 마지막 글자만 반복 추가\n",
        "            predict_str += char_set[result[-1]]\n",
        "\n",
        "    print(predict_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgE1nI1CKHDB",
        "outputId": "80e7b16f-fe5d-4516-a9f5-d233ee13108c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " t                                                                                                                                                                                 \n",
            " ,                                                                                                                                                                                 \n",
            "uuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuu\n",
            "utttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n",
            " tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n",
            " tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n",
            " t                                                                                                                                                                                 \n",
            "lt                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n",
            " tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n",
            " teeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            "ut                                                                                                                                                                                 \n",
            "ut                                                                                                                                                                                 \n",
            "ut                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            "lt                                                                                                                                                                                 \n",
            "lt                                                                                                                                                                                 \n",
            "lt                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n",
            " t                                                                                                                                                                                 \n"
          ]
        }
      ]
    }
  ]
}